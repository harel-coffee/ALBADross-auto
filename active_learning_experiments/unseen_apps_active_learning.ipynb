{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7941d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "335934f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded09c24",
   "metadata": {},
   "source": [
    "Options: \n",
    "\n",
    "* 1: Selects one app from each cluster\n",
    "\n",
    "* 2: Select num_train_apps and use the remaining for the testing. If num_train_apps is 3, train with 3 apps and use the remaining apps in the testing. Repeat that for all combinations, e.g., 11 combinations 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecbc5f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json \n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)-7s %(message)s',\n",
    "                    stream=sys.stderr, level=logging.INFO)\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.INFO)\n",
    "\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "\n",
    "#General ML \n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, silhouette_score,confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from modules.clustering_helpers import select_labeled_samples\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Active Learning\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling, margin_sampling, entropy_sampling\n",
    "\n",
    "\n",
    "#In-house Module Imports\n",
    "from config import Configuration \n",
    "from datasets import EclipseSampledDataset, VoltaSampledDataset\n",
    "from utils import *\n",
    "\n",
    "def random_sampling(classifier, X_pool):\n",
    "    n_samples = len(X_pool)\n",
    "    query_idx = np.random.choice(range(n_samples))\n",
    "    return query_idx, X_pool[query_idx]\n",
    "\n",
    "\n",
    "def call_FAR_function(false_alarm_rates,anomaly_miss_rates, test_label, y_pred, conf):\n",
    "    false_alarm_rate, anom_miss_rate = FAR_AMR_Calculate(\n",
    "            true_label= test_label['anom'].to_numpy(),\n",
    "            pred_label= y_pred,\n",
    "            result_dir= str(conf['results_dir']),\n",
    "            save_name= \"\",\n",
    "            save=False,\n",
    "            verbose=False,\n",
    "    )\n",
    "    false_alarm_rates.append(false_alarm_rate)\n",
    "    anomaly_miss_rates.append(anom_miss_rate)\n",
    "\n",
    "query_strategy_dict = {\n",
    "                       \"uncertainty\": uncertainty_sampling, \n",
    "                       \"margin\": margin_sampling, \n",
    "                       \"entropy\": entropy_sampling,\n",
    "                       \"random\": random_sampling\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8470ec57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 16:56:58,867 WARNING Are you sure that you are: aksar?\n"
     ]
    }
   ],
   "source": [
    "user = \"aksar\"\n",
    "logging.warning(f'Are you sure that you are: {user}?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffbe3d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIG = \"implementation_exp_2_active_learning\"  # change this\n",
    "SYSTEM = 'volta'  # volta or eclipse\n",
    "FE_NAME = 'mvts' #tsfresh, or mvts => It will set the EXP_NAME. Be careful. \n",
    "NUM_FEATURE = 2000  # example: 250 ,2000, 4000\n",
    "query_strategy = \"uncertainty\"  # \"uncertainty\", \"margin\", \"entropy\", \"random\"\n",
    "CV_INDEX = 0  # it can be integer value within the range 0 1 2 3 4\n",
    "repeat_num = 0\n",
    "query_size = 50\n",
    "classifier_name = 'rf'\n",
    "option = 2\n",
    "num_train_apps = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7bf4599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 16:57:00,576 WARNING Results will be generated in implementation_exp_2_active_learning, double check please!\n"
     ]
    }
   ],
   "source": [
    "#Constants\n",
    "FS_NAME = \"CHI\"\n",
    "method = \"random\" if query_strategy == 'random' else \"active_learning\"\n",
    "num_samples_per_pair = 1\n",
    "OUTPUT_DIR = f'/projectnb/peaclab-mon/{user}/active_learning_experiments'\n",
    "EXP_NAME = f'{FE_NAME}_experiments'\n",
    "FEATURE_SELECTION = False\n",
    "SCALER = 'None' #For now, do the scaling inside the notebook, then you can move that to the class function\n",
    "\n",
    "logging.warning('Results will be generated in {}, double check please!'.format(MODEL_CONFIG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68b910a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 16:57:00,785 WARNING You set windowing False, but you are trying to define window_size parameter, it is automatically set to 0. Please double check.\n",
      "2022-04-16 16:57:00,785 INFO    Setting directory names\n",
      "2022-04-16 16:57:00,791 INFO    Model config folder already exists, be careful, otherwise it will overwrite!\n",
      "2022-04-16 16:57:00,796 INFO    Saving configuration as CSV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# The configuration used for this run:\n",
      "# {'cv_fold': 0,\n",
      "#  'exp_name': 'mvts_experiments',\n",
      "#  'experiment_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments/volta/mvts_experiments'),\n",
      "#  'feature_extract': False,\n",
      "#  'feature_select': False,\n",
      "#  'hdf_data_path': PosixPath('/projectnb/peaclab-mon/aksar/datasets/tpds_data_hdfs'),\n",
      "#  'metadata_path': None,\n",
      "#  'model_config': 'implementation_exp_2_active_learning',\n",
      "#  'model_config_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments/volta/mvts_experiments/CV_0/implementation_exp_2_active_learning'),\n",
      "#  'model_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments/volta/mvts_experiments/CV_0/implementation_exp_2_active_learning/model'),\n",
      "#  'num_split': 5,\n",
      "#  'operation': 'read',\n",
      "#  'output_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments/volta'),\n",
      "#  'plots_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments/volta/mvts_experiments/CV_0/implementation_exp_2_active_learning/model/plots'),\n",
      "#  'processed_ldms_data_path': None,\n",
      "#  'raw_ldms_data_path': None,\n",
      "#  'results_dir': PosixPath('/projectnb/peaclab-mon/aksar/active_learning_experiments/volta/mvts_experiments/CV_0/implementation_exp_2_active_learning/results'),\n",
      "#  'runtime_testing_dir': None,\n",
      "#  'system': 'volta',\n",
      "#  'window_size': 0,\n",
      "#  'windowing': False}\n"
     ]
    }
   ],
   "source": [
    "conf = Configuration(ipython=True,\n",
    "                     overrides={\n",
    "                         'output_dir': Path(OUTPUT_DIR), #change\n",
    "                         'system' : SYSTEM,\n",
    "                         'exp_name':EXP_NAME,                                                  \n",
    "                         'cv_fold':CV_INDEX, \n",
    "                         'model_config': MODEL_CONFIG,\n",
    "                     })\n",
    "\n",
    "with open(str(conf['experiment_dir']) + '/anom_dict.json') as f:\n",
    "    ANOM_DICT = json.load(f)\n",
    "with open(str(conf['experiment_dir']) + '/app_dict.json') as f:\n",
    "    APP_DICT = json.load(f) \n",
    "    \n",
    "APP_REVERSE_DICT = {}\n",
    "for app_name, app_encoding in APP_DICT.items():\n",
    "    APP_REVERSE_DICT[app_encoding] = app_name    \n",
    "\n",
    "ANOM_REVERSE_DICT = {}\n",
    "for anom_name, anom_encoding in ANOM_DICT.items():\n",
    "    ANOM_REVERSE_DICT[anom_encoding] = anom_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac52eb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 16:57:01,027 INFO    BaseDataset Class Initialization\n",
      "2022-04-16 16:57:01,028 INFO    HPCDataset Class Initialization\n",
      "2022-04-16 16:57:01,029 INFO    VoltaSampledDataset Class Initialization\n",
      "2022-04-16 16:58:04,260 INFO    Train data shape (6326, 5633)\n",
      "2022-04-16 16:58:04,263 INFO    Train label shape (6326, 2)\n",
      "2022-04-16 16:58:04,264 INFO    Test data shape (14589, 5633)\n",
      "2022-04-16 16:58:04,265 INFO    Test label shape (14589, 2)\n",
      "2022-04-16 16:58:04,276 WARNING Beware that no scaling method is applied\n",
      "2022-04-16 16:58:08,900 INFO    Train data shape (6326, 5445)\n",
      "2022-04-16 16:58:08,901 INFO    Train label shape (6326, 4)\n",
      "2022-04-16 16:58:08,901 INFO    Test data shape (14589, 5445)\n",
      "2022-04-16 16:58:08,902 INFO    Test label shape (14589, 4)\n",
      "2022-04-16 16:58:08,908 INFO    Train data label dist: \n",
      "0    5694\n",
      "2     159\n",
      "4     159\n",
      "1     158\n",
      "3     156\n",
      "Name: anom, dtype: int64\n",
      "2022-04-16 16:58:08,912 INFO    Test data label dist: \n",
      "0    13286\n",
      "1      332\n",
      "2      326\n",
      "3      324\n",
      "4      321\n",
      "Name: anom, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "if SYSTEM == 'eclipse':\n",
    "    eclipseDataset = EclipseSampledDataset(conf)\n",
    "    train_data, train_label, test_data, test_label = eclipseDataset.load_dataset(scaler=SCALER,\n",
    "                                                                                 cv_fold=CV_INDEX,\n",
    "                                                                                 borghesi=False, \n",
    "                                                                                 mvts=True if FE_NAME == 'mvts' else False, \n",
    "                                                                                 tsfresh=True if FE_NAME == 'tsfresh' else False)\n",
    "\n",
    "elif SYSTEM == 'volta':\n",
    "    voltaDataset = VoltaSampledDataset(conf)\n",
    "    train_data, train_label, test_data, test_label = voltaDataset.load_dataset(scaler=SCALER,\n",
    "                                                                               cv_fold=CV_INDEX,\n",
    "                                                                               borghesi=False,\n",
    "                                                                               mvts=True if FE_NAME == 'mvts' else False,\n",
    "                                                                               tsfresh=True if FE_NAME == 'tsfresh' else False)\n",
    "\n",
    "assert list(train_data.index) == list(train_label.index) #check the order of the labels     \n",
    "assert list(test_data.index) == list(test_label.index) #check the order of the labels    \n",
    "\n",
    "if FEATURE_SELECTION:\n",
    "    selected_features = pd.read_csv(conf['experiment_dir'] / 'selected_features.csv')\n",
    "    train_data = train_data[list(selected_features['0'].values)]\n",
    "    test_data = test_data[list(selected_features['0'].values)]\n",
    "    \n",
    "train_label['anom_names'] = train_label.apply(lambda x: ANOM_REVERSE_DICT[x['anom']], axis=1)\n",
    "train_label['app_names']=train_label['app'].apply(lambda x: APP_REVERSE_DICT[x])\n",
    "test_label['anom_names'] = test_label.apply(lambda x: ANOM_REVERSE_DICT[x['anom']], axis=1)\n",
    "test_label['app_names']=test_label['app'].apply(lambda x: APP_REVERSE_DICT[x])\n",
    "\n",
    "all_data = pd.concat([train_data, test_data])\n",
    "all_data = all_data.dropna(axis=1, how='any')\n",
    "all_label = pd.concat([train_label,test_label])\n",
    "\n",
    "train_data = all_data.loc[train_label.index]\n",
    "test_data = all_data.loc[test_label.index]\n",
    "    \n",
    "logging.info(\"Train data shape %s\",train_data.shape)\n",
    "logging.info(\"Train label shape %s\",train_label.shape)\n",
    "logging.info(\"Test data shape %s\",test_data.shape)  \n",
    "logging.info(\"Test label shape %s\",test_label.shape)\n",
    "\n",
    "logging.info(\"Train data label dist: \\n%s\",train_label['anom'].value_counts())\n",
    "logging.info(\"Test data label dist: \\n%s\",test_label['anom'].value_counts())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fbb2339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 16:58:11,973 INFO    (6326, 2000)\n",
      "2022-04-16 16:58:11,974 INFO    (14589, 2000)\n"
     ]
    }
   ],
   "source": [
    "SCALER = 'MinMax'\n",
    "\n",
    "if SCALER == 'MinMax':\n",
    "    \n",
    "    minmax_scaler = MinMaxScaler().fit(train_data)\n",
    "    train_data = pd.DataFrame(minmax_scaler.transform(train_data),columns=train_data.columns,index=train_data.index)\n",
    "    test_data = pd.DataFrame(minmax_scaler.transform(test_data),columns=test_data.columns,index=test_data.index)\n",
    "    \n",
    "elif SCALER == 'Standard':\n",
    "    \n",
    "    # Standardize data (per feature Z-normalization, i.e. zero-mean and unit variance)        \n",
    "    scaler = StandardScaler().fit(train_data)\n",
    "    train_data = pd.DataFrame(scaler.transform(train_data),columns=train_data.columns,index=train_data.index)\n",
    "    test_data = pd.DataFrame(scaler.transform(test_data),columns=test_data.columns,index=test_data.index)  \n",
    "    \n",
    "#Implement new feature selection strategies below\n",
    "if FS_NAME == 'CHI':\n",
    "    \n",
    "    selector = SelectKBest(chi2, k=NUM_FEATURE)\n",
    "    selector.fit(train_data,train_label['anom'])\n",
    "    train_data = train_data[train_data.columns[selector.get_support(indices=True)]]\n",
    "    selected_columns = train_data.columns\n",
    "    test_data = test_data[test_data.columns & selected_columns]\n",
    "    \n",
    "elif FS_NAME == 'TSFRESH':\n",
    "    logging.warning(\"NUM_FEATURE parameter will be overwritten by the automatic selection process\")\n",
    "    \n",
    "    y_train = train_label['anom']\n",
    "    X_train = train_data\n",
    "\n",
    "    relevant_features = set()\n",
    "\n",
    "    for label in y_train.unique():\n",
    "        y_train_binary = y_train == label\n",
    "        X_train_filtered = tsfresh.select_features(X_train, y_train_binary)\n",
    "        print(\"Number of relevant features for class {}: {}/{}\".format(label, X_train_filtered.shape[1], X_train.shape[1]))\n",
    "        relevant_features = relevant_features.union(set(X_train_filtered.columns))    \n",
    "    train_data = train_data[relevant_features]\n",
    "    test_data = test_data[relevant_features]\n",
    "    NUM_FEATURE = len(relevant_features)\n",
    "    \n",
    "elif FS_NAME == 'NONE':\n",
    "    logging.info(\"No feature selection strategy is specified, will be using all features\")\n",
    "    NUM_FEATURE = len(train_data.columns)\n",
    "    \n",
    "logging.info(train_data.shape)\n",
    "logging.info(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5608149d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 16:58:12,043 INFO    Labeled data label dist: \n",
      "4    12\n",
      "3    11\n",
      "2    11\n",
      "1    11\n",
      "0    11\n",
      "Name: anom, dtype: int64\n",
      "2022-04-16 16:58:12,046 INFO    Unlabeled data label dist: \n",
      "0    5683\n",
      "2     148\n",
      "1     147\n",
      "4     147\n",
      "3     145\n",
      "Name: anom, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Read the node_ids considered labeled\n",
    "labeled_train_label = pd.read_csv(conf['experiment_dir'] / f'CV_{CV_INDEX}'/ f'labeled_train_label_{num_samples_per_pair}.csv', index_col=['node_id'])\n",
    "labeled_test_label = pd.read_csv(conf['experiment_dir'] / f'CV_{CV_INDEX}'/ f'labeled_test_label_{num_samples_per_pair}.csv', index_col=['node_id'])\n",
    "node_indices_labeled = list(labeled_train_label['anom'].index.values)\n",
    "\n",
    "logging.info(\"Labeled data label dist: \\n%s\",labeled_train_label['anom'].value_counts())\n",
    "logging.info(\"Unlabeled data label dist: \\n%s\",labeled_test_label['anom'].value_counts())\n",
    "\n",
    "#Set a new column for label status\n",
    "node_indices_unlabeled = []\n",
    "for node in train_label.index:\n",
    "    if node not in node_indices_labeled:\n",
    "        node_indices_unlabeled.append(node)\n",
    "train_label['label_status'] = train_label['anom'] # for the full data case\n",
    "train_label['label_status'] = np.where(train_label.index.get_level_values('node_id').isin(node_indices_unlabeled), -1,train_label['label_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e79a28a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial_labeled_pool contains one sample from each application anomaly pair\n",
    "initial_labeled_pool = train_label[(train_label['label_status'] != -1)]\n",
    "#Active learning or random sampling will be querying from the same pool\n",
    "initial_unlabeled_pool = train_label[(train_label['label_status'] == -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52427afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if classifier_name == 'rf':\n",
    "    selected_classifier = RandomForestClassifier()\n",
    "elif classifier_name == 'lr':\n",
    "    selected_classifier = LogisticRegression()\n",
    "else:\n",
    "    selected_classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08c4f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nas_apps = ['lu','sp','ft','bt','cg','mg']\n",
    "mantevo_apps = ['miniMD','CoMD','miniGhost','miniAMR']\n",
    "other_apps = ['kripke']\n",
    "\n",
    "all_app_names = list(APP_DICT.keys())\n",
    "\n",
    "assert set(nas_apps + mantevo_apps + other_apps) == set(all_app_names)\n",
    "\n",
    "#Heuristic according to the hiarchical clustering\n",
    "cluster_one = ['ft','cg','mg']\n",
    "cluster_two = ['miniAMR','lu','miniGhost']\n",
    "cluster_three = ['sp','bt','miniMD','kripke','CoMD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dec1342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 16:58:12,176 INFO    Total number of combinations: 55\n"
     ]
    }
   ],
   "source": [
    "all_test_app_groups = []\n",
    "all_train_app_groups = []\n",
    "\n",
    "if option == 1:\n",
    "\n",
    "    for app_one in cluster_one:\n",
    "        for app_two in cluster_two:\n",
    "            for app_three in cluster_three:\n",
    "                temp_app_list = [app_one,app_two,app_three]\n",
    "                all_test_app_groups.append(temp_app_list)\n",
    "                all_train_app_groups.append(list(set(all_app_names) - set(temp_app_list)))\n",
    "                \n",
    "elif option == 2:\n",
    "    \n",
    "    for temp_app_list in list(combinations(all_app_names,num_train_apps)):\n",
    "        all_train_app_groups.append(temp_app_list)        \n",
    "        all_test_app_groups.append(list(set(all_app_names) - set(temp_app_list)))\n",
    "\n",
    "num_test_apps = len(all_test_app_groups[0]) #this is constant\n",
    "total_num_train_apps =  len(all_app_names) - num_test_apps        \n",
    "logging.info(\"Total number of combinations: %s\", len(all_train_app_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfb12c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "scores = pd.DataFrame()\n",
    "\n",
    "for test_apps, train_apps in zip(all_test_app_groups, all_train_app_groups):\n",
    "    \n",
    "    selected_apps= dict.fromkeys(all_app_names,0)\n",
    "    selected_anoms= dict.fromkeys(list(ANOM_REVERSE_DICT.keys()),0)\n",
    "    \n",
    "    logging.info(\"Test apps: %s\", test_apps)\n",
    "    logging.info(\"Train apps: %s\", train_apps)\n",
    "\n",
    "    test_apps_label = test_label[test_label['app_names'].isin(test_apps)]\n",
    "    assert set(test_apps_label['app_names'].unique()) == set(test_apps)\n",
    "    test_apps_data = test_data.loc[test_apps_label.index]\n",
    "    assert list(test_apps_data.index) == list(test_apps_label.index)\n",
    "\n",
    "    #Create the label and data for the starting condition composed of selected apps \n",
    "    y_initial = initial_labeled_pool[initial_labeled_pool['app_names'].isin(train_apps)]\n",
    "    x_initial = train_data[train_data.index.get_level_values('node_id').isin(y_initial.index)]\n",
    "\n",
    "    y_initial = y_initial['anom'].to_numpy()\n",
    "    x_initial = x_initial.to_numpy()                \n",
    "\n",
    "    x_unlabeled = train_data[train_data.index.get_level_values('node_id').isin(initial_unlabeled_pool.index)]\n",
    "    y_unlabeled = initial_unlabeled_pool#['anom'].to_numpy()\n",
    "    x_unlabeled = x_unlabeled.to_numpy()      \n",
    "    logging.info(\"Unlabeled pool apps: %s\", y_unlabeled['app_names'].unique())    \n",
    "\n",
    "    #Initializations\n",
    "    macro_f1_scores = []\n",
    "    anomaly_miss_rates = []\n",
    "    false_alarm_rates = []\n",
    "    \n",
    "    if query_strategy != \"random\":         \n",
    "        selected_indices_apps = []\n",
    "        selected_indices_anoms = []        \n",
    "\n",
    "    X_pool = x_unlabeled.copy()\n",
    "    y_pool = y_unlabeled.copy() \n",
    "    y_pool_anom = y_pool['anom'].to_numpy()\n",
    "    y_pool_app = y_pool['app_names'].to_numpy()                \n",
    "\n",
    "    learner = ActiveLearner(\n",
    "        estimator=RandomForestClassifier(),\n",
    "        query_strategy=query_strategy_dict[query_strategy],\n",
    "        X_training=x_initial, y_training=y_initial\n",
    "    )        \n",
    "\n",
    "    logging.info(\"Test apps label check: %s\", test_apps_label['app_names'].unique())\n",
    "    y_pred = learner.predict(test_apps_data.to_numpy())\n",
    "    report_dict = classification_report(test_apps_label['anom'].to_numpy(), y_pred, output_dict = True)\n",
    "    macro_f1_scores.append(report_dict['macro avg']['f1-score'])                                        \n",
    "    call_FAR_function(false_alarm_rates,anomaly_miss_rates, test_apps_label, y_pred, conf)\n",
    "\n",
    "    for i in range(query_size):\n",
    "        query_idx, query_sample = learner.query(X_pool)\n",
    "\n",
    "        if query_strategy != \"random\":\n",
    "            selected_indices_apps.append(y_pool_app[query_idx][0])\n",
    "            selected_indices_anoms.append(y_pool_anom[query_idx][0])\n",
    "\n",
    "        learner.teach(\n",
    "            X=X_pool[query_idx].reshape(1,-1),\n",
    "            y=y_pool_anom[query_idx].reshape(1,)\n",
    "        )\n",
    "\n",
    "        X_pool, y_pool_anom, y_pool_app = np.delete(X_pool, query_idx, axis=0), np.delete(y_pool_anom, query_idx, axis=0), np.delete(y_pool_app, query_idx, axis=0)\n",
    "        y_pred = learner.predict(test_apps_data.to_numpy())              \n",
    "\n",
    "        report_dict = classification_report(test_apps_label['anom'].to_numpy(), y_pred, output_dict = True)\n",
    "        macro_f1_scores.append(report_dict['macro avg']['f1-score'])                                        \n",
    "        call_FAR_function(false_alarm_rates,anomaly_miss_rates, test_apps_label, y_pred, conf)    \n",
    "\n",
    "    for j in range(len(macro_f1_scores)):\n",
    "        scores = scores.append({'query_iter':j,\n",
    "                                'macro_avg_f1_score':macro_f1_scores[j],\n",
    "                                'false_alarm_rate':false_alarm_rates[j],\n",
    "                                'anomaly_miss_rate':anomaly_miss_rates[j], \n",
    "                                'repeat_num':repeat_num},\n",
    "                               ignore_index = True)\n",
    "\n",
    "    scores['fold'] = CV_INDEX\n",
    "    scores['method'] = method\n",
    "    scores['query_strategy'] = query_strategy\n",
    "    scores['model'] = selected_classifier.__class__.__name__\n",
    "    scores['dataset'] = SYSTEM\n",
    "    scores['fe'] = FE_NAME\n",
    "    scores['feature_count'] = NUM_FEATURE   \n",
    "    scores['query_size'] = query_size\n",
    "\n",
    "    scores = scores.sort_values(by = ['query_iter']).reset_index(drop = True)\n",
    "   \n",
    "    train_app_names = '-'.join(train_apps)\n",
    "    test_app_names = '-'.join(test_apps)\n",
    "\n",
    "    filename = f'train:{train_app_names}#test:{test_app_names}#{FE_NAME}#{NUM_FEATURE}#{method}#{query_strategy}#{query_size}#{selected_classifier.__class__.__name__}#{repeat_num}.csv'\n",
    "    scores.to_csv(Path(conf[\"results_dir\"]) / filename)   \n",
    "\n",
    "    logging.info(\"Saving: %s\", filename)\n",
    "    \n",
    "    if query_strategy != \"random\":\n",
    "        selected_app_anom_df = pd.DataFrame()\n",
    "        selected_app_anom_df['apps'] = selected_indices_apps\n",
    "        selected_app_anom_df['anoms'] = selected_indices_anoms\n",
    "        selected_app_anom_df.to_csv(\n",
    "        Path(conf[\"results_dir\"])\n",
    "        / f\"train:{train_app_names}#test:{test_app_names}#{FE_NAME}#{NUM_FEATURE}#{method}#{query_strategy}#{query_size}#{selected_classifier.__class__.__name__}#{repeat_num}#app-anom-selection.csv\",\n",
    "        index=False)\n",
    "        logging.info(\"Saved selected apps and anoms\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2941b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
