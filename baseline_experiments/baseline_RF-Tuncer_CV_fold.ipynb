{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "022f38cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f72bd74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7610f4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,sys\n",
    "from pathlib import Path\n",
    "import json \n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)-7s %(message)s',\n",
    "                    stream=sys.stderr, level=logging.INFO)\n",
    "mpl_logger = logging.getLogger('matplotlib')\n",
    "mpl_logger.setLevel(logging.INFO)\n",
    "\n",
    "#General ML \n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "#In-house Module Imports\n",
    "from config import Configuration \n",
    "from datasets import EclipseSampledDataset\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18599777",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 12:35:29,161 WARNING Are you sure that you are: sencan?\n"
     ]
    }
   ],
   "source": [
    "user = \"sencan\"\n",
    "logging.warning(f'Are you sure that you are: {user}?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71e9a361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 12:35:30,583 WARNING Results will be generated in baseline_debug, double check please!\n"
     ]
    }
   ],
   "source": [
    "#Update these if you are not the desired user\n",
    "OUTPUT_DIR = f'/projectnb/peaclab-mon/{user}/feature_extraction_experiments'\n",
    "SYSTEM = 'eclipse'\n",
    "EXP_NAME = 'tsfresh_experiments'\n",
    "CV_INDEX = 0\n",
    "FEATURE_SELECTION = False\n",
    "SCALER = 'None' #For now, do the scaling inside the notebook, then you can move that to the class function\n",
    "MODEL_CONFIG = 'baseline_debug'\n",
    "logging.warning('Results will be generated in {}, double check please!'.format(MODEL_CONFIG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a3ca146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 12:35:32,309 WARNING You set windowing False, but you are trying to define window_size parameter, it is automatically set to 0. Please double check.\n",
      "2022-01-21 12:35:32,309 INFO    Setting directory names\n",
      "2022-01-21 12:35:32,316 INFO    Model config folder already exists, be careful, otherwise it will overwrite!\n",
      "2022-01-21 12:35:32,319 INFO    Saving configuration as CSV\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# The configuration used for this run:\n",
      "# {'cv_fold': 0,\n",
      "#  'exp_name': 'tsfresh_experiments',\n",
      "#  'experiment_dir': PosixPath('/projectnb/peaclab-mon/sencan/feature_extraction_experiments/eclipse/tsfresh_experiments'),\n",
      "#  'feature_extract': False,\n",
      "#  'feature_select': False,\n",
      "#  'hdf_data_path': PosixPath('/projectnb/peaclab-mon/aksar/datasets/eclipse_sampled_hdfs'),\n",
      "#  'metadata_path': None,\n",
      "#  'model_config': 'cluster_then_predict',\n",
      "#  'model_config_dir': PosixPath('/projectnb/peaclab-mon/sencan/feature_extraction_experiments/eclipse/tsfresh_experiments/CV_0/cluster_then_predict'),\n",
      "#  'model_dir': PosixPath('/projectnb/peaclab-mon/sencan/feature_extraction_experiments/eclipse/tsfresh_experiments/CV_0/cluster_then_predict/model'),\n",
      "#  'num_split': 5,\n",
      "#  'operation': 'read',\n",
      "#  'output_dir': PosixPath('/projectnb/peaclab-mon/sencan/feature_extraction_experiments/eclipse'),\n",
      "#  'plots_dir': PosixPath('/projectnb/peaclab-mon/sencan/feature_extraction_experiments/eclipse/tsfresh_experiments/CV_0/cluster_then_predict/model/plots'),\n",
      "#  'processed_ldms_data_path': None,\n",
      "#  'raw_ldms_data_path': None,\n",
      "#  'results_dir': PosixPath('/projectnb/peaclab-mon/sencan/feature_extraction_experiments/eclipse/tsfresh_experiments/CV_0/cluster_then_predict/results'),\n",
      "#  'runtime_testing_dir': None,\n",
      "#  'system': 'eclipse',\n",
      "#  'window_size': 0,\n",
      "#  'windowing': False}\n"
     ]
    }
   ],
   "source": [
    "conf = Configuration(ipython=True,\n",
    "                     overrides={\n",
    "                         'output_dir': Path(OUTPUT_DIR), #change\n",
    "                         'system' : SYSTEM,\n",
    "                         'exp_name':EXP_NAME,                                                  \n",
    "                         'cv_fold':CV_INDEX, \n",
    "                         'model_config': 'cluster_then_predict',\n",
    "                     })\n",
    "\n",
    "with open(str(conf['experiment_dir']) + '/anom_dict.json') as f:\n",
    "    ANOM_DICT = json.load(f)\n",
    "with open(str(conf['experiment_dir']) + '/app_dict.json') as f:\n",
    "    APP_DICT = json.load(f)    \n",
    "    \n",
    "APP_REVERSE_DICT = {}\n",
    "for app_name, app_encoding in APP_DICT.items():\n",
    "    APP_REVERSE_DICT[app_encoding] = app_name    \n",
    "\n",
    "ANOM_REVERSE_DICT = {}\n",
    "for anom_name, anom_encoding in ANOM_DICT.items():\n",
    "    ANOM_REVERSE_DICT[anom_encoding] = anom_name        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b545ef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 12:35:39,484 INFO    BaseDataset Class Initialization\n",
      "2022-01-21 12:35:39,484 INFO    HPCDataset Class Initialization\n",
      "2022-01-21 12:35:39,485 INFO    EclipseSampledDataset Class Initialization\n",
      "2022-01-21 12:36:21,859 INFO    Train data shape (1351, 121836)\n",
      "2022-01-21 12:36:21,860 INFO    Train label shape (1351, 2)\n",
      "2022-01-21 12:36:21,861 INFO    Test data shape (2462, 121836)\n",
      "2022-01-21 12:36:21,861 INFO    Test label shape (2462, 2)\n",
      "2022-01-21 12:36:21,863 WARNING Beware that no scaling method is applied\n",
      "2022-01-21 12:36:31,423 INFO    Train data shape (1351, 115159)\n",
      "2022-01-21 12:36:31,425 INFO    Train label shape (1351, 3)\n",
      "2022-01-21 12:36:31,426 INFO    Test data shape (2462, 115159)\n",
      "2022-01-21 12:36:31,426 INFO    Test label shape (2462, 3)\n",
      "2022-01-21 12:36:31,428 INFO    Train data label dist: \n",
      "0    1217\n",
      "2      34\n",
      "1      34\n",
      "4      33\n",
      "3      33\n",
      "Name: anom, dtype: int64\n",
      "2022-01-21 12:36:31,431 INFO    Test data label dist: \n",
      "1    542\n",
      "2    542\n",
      "3    539\n",
      "4    536\n",
      "0    303\n",
      "Name: anom, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "eclipseDataset = EclipseSampledDataset(conf)\n",
    "train_data, train_label, test_data, test_label = eclipseDataset.load_dataset(scaler=SCALER,borghesi=False,tsfresh = True)\n",
    "assert list(train_data.index) == list(train_label.index) #check the order of the labels     \n",
    "assert list(test_data.index) == list(test_label.index) #check the order of the labels    \n",
    "\n",
    "if FEATURE_SELECTION:\n",
    "    selected_features = pd.read_csv(conf['experiment_dir'] / 'selected_features.csv')\n",
    "    train_data = train_data[list(selected_features['0'].values)]\n",
    "    test_data = test_data[list(selected_features['0'].values)]\n",
    "    \n",
    "train_label['anom_names'] = train_label.apply(lambda x: ANOM_REVERSE_DICT[x['anom']], axis=1)\n",
    "test_label['anom_names'] = test_label.apply(lambda x: ANOM_REVERSE_DICT[x['anom']], axis=1)\n",
    "\n",
    "all_data = pd.concat([train_data, test_data])\n",
    "all_data = all_data.dropna(axis=1, how='any')\n",
    "all_label = pd.concat([train_label,test_label])\n",
    "\n",
    "train_data = all_data.loc[train_label.index]\n",
    "test_data = all_data.loc[test_label.index]\n",
    "    \n",
    "logging.info(\"Train data shape %s\",train_data.shape)\n",
    "logging.info(\"Train label shape %s\",train_label.shape)\n",
    "logging.info(\"Test data shape %s\",test_data.shape)  \n",
    "logging.info(\"Test label shape %s\",test_label.shape)\n",
    "\n",
    "logging.info(\"Train data label dist: \\n%s\",train_label['anom'].value_counts())\n",
    "logging.info(\"Test data label dist: \\n%s\",test_label['anom'].value_counts())        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250e3d39",
   "metadata": {},
   "source": [
    "If we do not apply feature selection we would have 8866 columns in total and 7150 of them would be per core metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd7f44",
   "metadata": {},
   "source": [
    "#### After Feature Selection Check How Many Per Core Metrics are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ee396",
   "metadata": {},
   "source": [
    "After feature selection we have 2344 columns in total, 1939 of them are per core metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63b558e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1939\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for col in train_data.columns:\n",
    "    if 'per_core' in col:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85a724b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALER = 'MinMax'\n",
    "\n",
    "if SCALER == 'MinMax':\n",
    "    \n",
    "    scaler = MinMaxScaler()    \n",
    "\n",
    "elif SCALER == 'Standard':\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "pipeline = Pipeline([('transformer', scaler), ('estimator', clf)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b197ac",
   "metadata": {},
   "source": [
    "### Running FR Tuncer with MVTS/Tsfresh Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5343fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALER = 'MinMax'\n",
    "\n",
    "if SCALER == 'MinMax':\n",
    "    \n",
    "    minmax_scaler = MinMaxScaler().fit(train_data)\n",
    "    train_data = pd.DataFrame(minmax_scaler.transform(train_data),columns=train_data.columns,index=train_data.index)\n",
    "    test_data = pd.DataFrame(minmax_scaler.transform(test_data),columns=test_data.columns,index=test_data.index)\n",
    "    \n",
    "elif SCALER == 'Standard':\n",
    "    \n",
    "    # Standardize data (per feature Z-normalization, i.e. zero-mean and unit variance)        \n",
    "    scaler = StandardScaler().fit(train_data)\n",
    "    train_data = pd.DataFrame(scaler.transform(train_data),columns=train_data.columns,index=train_data.index)\n",
    "    test_data = pd.DataFrame(scaler.transform(test_data),columns=test_data.columns,index=test_data.index)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8723a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 12:36:43,768 INFO    (1351, 20000)\n",
      "2022-01-21 12:36:43,769 INFO    (2462, 20000)\n",
      "2022-01-21 12:36:44,750 INFO    (3813, 20000)\n",
      "2022-01-21 12:36:44,751 INFO    (3813, 3)\n"
     ]
    }
   ],
   "source": [
    "NEW_FS = True\n",
    "NUM_FEATURES = 20000\n",
    "\n",
    "if NEW_FS:\n",
    "    selector = SelectKBest(chi2, k=NUM_FEATURES)\n",
    "    selector.fit(train_data,train_label['anom'])\n",
    "    train_data = train_data[train_data.columns[selector.get_support(indices=True)]]\n",
    "    selected_columns = train_data.columns\n",
    "    test_data = test_data[test_data.columns & selected_columns]\n",
    "    \n",
    "logging.info(train_data.shape)\n",
    "logging.info(test_data.shape)\n",
    "\n",
    "all_data = pd.concat([train_data, test_data])\n",
    "all_data = all_data.dropna(axis=1, how='any')\n",
    "all_label = pd.concat([train_label,test_label])\n",
    "\n",
    "logging.info(all_data.shape)\n",
    "logging.info(all_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0116b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "pipeline = Pipeline([('estimator', clf)])\n",
    "#pipeline = Pipeline([('transformer', scaler), ('estimator', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "422be87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = ['precision_macro', 'recall_macro', 'f1_macro', 'f1_weighted']\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "scores = cross_validate(pipeline, all_data, all_label['anom'].values,                         \n",
    "                        cv=skf, \n",
    "                        scoring=scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52101fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([14.36127019, 14.22909045, 14.40623927, 14.01253319, 14.13402009]),\n",
       " 'score_time': array([0.38078332, 0.36517859, 0.36603427, 0.34352994, 0.36449242]),\n",
       " 'test_precision_macro': array([0.98951867, 0.98436177, 0.98784029, 0.98828084, 0.99238613]),\n",
       " 'test_recall_macro': array([0.98951945, 0.98434783, 0.98782609, 0.98778006, 0.99125858]),\n",
       " 'test_f1_macro': array([0.98951166, 0.98434753, 0.98782586, 0.987894  , 0.99180277]),\n",
       " 'test_f1_weighted': array([0.99212481, 0.98820423, 0.99082551, 0.99085529, 0.99343037])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adcf6720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9910880447994387"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tsfresh results with 20k feature\n",
    "scores['test_f1_weighted'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "213406de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9826724483115286"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mvts results\n",
    "scores['test_f1_weighted'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7efd4b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.923437823541215"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results after using per core metrics with feature selection (previously it was 0.90)\n",
    "scores['test_f1_weighted'].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
